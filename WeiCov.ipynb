{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NB-IoT Localization - WKNN",
   "id": "a4b55a4963188ba4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "e71a8838d2d44c29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:38:28.936816Z",
     "start_time": "2024-09-23T15:38:26.890868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.data_loader import load_matlab_file_as_df\n",
    "\n",
    "# set options\n",
    "rf_param = 'NSINR'\n",
    "\n",
    "# source file\n",
    "BASE_DIR = \"data/\"\n",
    "FULL_DATA_SET = \"Campaign_data_NBIoT_1_2_3_4_5_6_interpolated_smoothed.mat\"\n",
    "filename = os.path.join(BASE_DIR, FULL_DATA_SET)\n",
    "\n",
    "# load the dataset as pandas dataframe\n",
    "df = load_matlab_file_as_df(\n",
    "    filename=filename,\n",
    "    dataset='dataSet_smooth',  # dataSet, dataSet_interp or dataSet_smooth\n",
    "    usecols=['lat', 'lng', 'measurements_matrix']\n",
    ")\n",
    "\n",
    "# better printing of dataframes\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # No limit on column width\n",
    "pd.set_option('display.width', 1000)  # Set the display width to 1000 characters\n",
    "\n",
    "# Set the probability for a point to be a test point\n",
    "TP_probability = 0.3\n",
    "\n",
    "# Randomly assign points as test points (2) or reference points (1)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "df['PointType'] = (np.random.rand(len(df)) <= TP_probability).astype(int) + 1\n",
    "df_rp = df[df['PointType'] == 1]\n",
    "df_tp = df[df['PointType'] == 2]"
   ],
   "id": "7a91f52a3c9e20f5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data processing",
   "id": "91d0e464f93528fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:38:29.822498Z",
     "start_time": "2024-09-23T15:38:28.940325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from scripts.weighted_coverage import create_point_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Get unique npcis\n",
    "npcis_rp = np.concatenate(df_rp['measurements_matrix'].apply(lambda x: x['NPCI'].values).values)\n",
    "npcis_tp = np.concatenate(df_tp['measurements_matrix'].apply(lambda x: x['NPCI'].values).values)\n",
    "\n",
    "all_npcis = np.concatenate([npcis_rp, npcis_tp])\n",
    "unique_npcis = np.unique(all_npcis)\n",
    "\n",
    "m_rfp, idx_rfp = create_point_matrix(df_rp, unique_npcis, rf_param)\n",
    "\n",
    "# Create matrices for test points \n",
    "m_tp, idx_tp = create_point_matrix(df_tp, unique_npcis, rf_param)"
   ],
   "id": "63533917984d1b29",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compute weights",
   "id": "c01a0e75622c8674"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:38:30.777994Z",
     "start_time": "2024-09-23T15:38:29.939351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Caclulate distances between tps and rps\n",
    "D = cdist(m_tp, m_rfp, metric='euclidean')\n",
    "\n",
    "# Normalize distances based on common NPCIs\n",
    "for i in range(m_tp.shape[0]):\n",
    "    match = np.logical_and(idx_tp[i, :], idx_rfp)\n",
    "    s = np.sum(match, axis=1)\n",
    "    z = np.where(s == 0)\n",
    "    nz = np.where(s != 0)\n",
    "\n",
    "    for j in nz[0]:\n",
    "        D[i, j] = D[i, j] / s[j]\n",
    "    for j in z[0]:\n",
    "        D[i, j] = np.inf  # Use np.inf to represent a very large distance\n",
    "\n",
    "# Set distances to dummy reference points to a very large value\n",
    "dummy_rfps = np.all(idx_rfp == 0, axis=1)\n",
    "D[:, dummy_rfps] = np.inf\n",
    "\n",
    "# Replace zero distances with a small value to avoid singularities\n",
    "D[D == 0] = np.min(D[D != 0]) / 20\n",
    "\n",
    "# Sort distances and compute weights\n",
    "D_sort = np.sort(D, axis=1)\n",
    "idx_sort = np.argsort(D, axis=1)\n",
    "W = 1.0 / D_sort"
   ],
   "id": "ccec98d76838c29",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## WKNN",
   "id": "5db5abb29ce32866"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:38:30.865405Z",
     "start_time": "2024-09-23T15:38:30.824794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scripts.haversine import haversine_distance\n",
    "\n",
    "num_tps = df_tp.shape[0]\n",
    "k_max = 40\n",
    "k_values = range(1, k_max + 1)\n",
    "TP_est_location = [None] * len(k_values)\n",
    "k_avg_error = {}\n",
    "\n",
    "# Extract real positions of test points\n",
    "real_lat = df_tp['lat'].values\n",
    "real_long = df_tp['lng'].values\n",
    "real_position = np.vstack((real_lat, real_long)).T\n",
    "\n",
    "# Loop over each k value\n",
    "for i, this_k in enumerate(k_values):\n",
    "    # Select the k-nearest reference points\n",
    "    RFP_selected_idx = idx_sort[:, :this_k]\n",
    "\n",
    "    # Extract coordinates of the selected reference points\n",
    "    lat_k_RFP_matrix = df_rp.iloc[RFP_selected_idx.flatten()]['lat'].values.reshape(RFP_selected_idx.shape)\n",
    "    long_k_RFP_matrix = df_rp.iloc[RFP_selected_idx.flatten()]['lng'].values.reshape(RFP_selected_idx.shape)\n",
    "\n",
    "    # Compute weighted sums of coordinates\n",
    "    sum_lat = np.sum(lat_k_RFP_matrix * W[:, :this_k], axis=1)\n",
    "    sum_long = np.sum(long_k_RFP_matrix * W[:, :this_k], axis=1)\n",
    "\n",
    "    # Compute estimated coordinates of test points\n",
    "    lat_k_TP = sum_lat / np.sum(W[:, :this_k], axis=1)\n",
    "    long_k_TP = sum_long / np.sum(W[:, :this_k], axis=1)\n",
    "\n",
    "    # Compute errors using Haversine formula\n",
    "    km_pow = haversine_distance(real_position[:, 0], real_position[:, 1], lat_k_TP, long_k_TP)\n",
    "    average_error_pow = np.mean(km_pow)\n",
    "\n",
    "    k_avg_error[this_k] = average_error_pow\n",
    "\n",
    "    # Store estimated locations\n",
    "    TP_est_location_k = np.zeros((num_tps, 2))\n",
    "    TP_est_location_k[:, 0] = lat_k_TP\n",
    "    TP_est_location_k[:, 1] = long_k_TP\n",
    "    TP_est_location[i] = TP_est_location_k\n"
   ],
   "id": "a647a91d19d6fa86",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:38:30.923134Z",
     "start_time": "2024-09-23T15:38:30.920952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "print(f'Average error with k = 3 {k_avg_error[3]}')"
   ],
   "id": "70f36e462eed4bcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error with k = 3 0.014426894600619732\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:38:30.978750Z",
     "start_time": "2024-09-23T15:38:30.977015Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b59ee652b1cb52fc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
